import tensorflow as tf
from tensorflow.keras import Model,Sequential
from tensorflow.keras.layers import TimeDistributed, LSTM, Dense,Masking, Flatten
from tensorflow.keras.callbacks import EarlyStopping
from typing import Tuple
from colorama import Fore, Style
import time
import numpy as np

def Initialize_model(frame:int):

    num_classes=250
    model = Sequential()
    model.add(TimeDistributed(Flatten(), input_shape=(frame, 75, 3)))
    model.add(LSTM(units=128))
    model.add(Dense(num_classes, activation='softmax'))
    return model

def Compile_model(model: Model, learning_rate:float):
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'],learning_rate=learning_rate)
    return model

def train_model(
        model: Model,
        X: np.ndarray,
        y: np.ndarray,
        batch_size=256,
        patience=2,
        validation_data=None,
        validation_split=0.3
    ) -> Tuple[Model, dict]:
    """
    Fit the model and return a tuple (fitted_model, history)
    """
    print(Fore.BLUE + "\nTraining model..." + Style.RESET_ALL)

    es = EarlyStopping(
        monitor="val_loss",
        patience=patience,
        restore_best_weights=True,
        verbose=1
    )

    history = model.fit(
        X,
        y,
        validation_data=validation_data,
        validation_split=validation_split,
        epochs=100,
        batch_size=batch_size,
        callbacks=[es],
        verbose=0
    )

    print(f"✅ Model trained on {len(X)} rows with min val MAE: {round(np.min(history.history['val_mae']), 2)}")

    return model, history

def evaluate_model(
        model: Model,
        X: np.ndarray,
        y: np.ndarray,
        batch_size=64
    ) -> Tuple[Model, dict]:
    """
    Evaluate trained model performance on the dataset
    """

    print(Fore.BLUE + f"\nEvaluating model on {len(X)} rows..." + Style.RESET_ALL)

    if model is None:
        print(f"\n❌ No model to evaluate")
        return None

    metrics = model.evaluate(
        x=X,
        y=y,
        batch_size=batch_size,
        verbose=0,
        # callbacks=None,
        return_dict=True
    )

    loss = metrics["loss"]
    mae = metrics["mae"]

    print(f"✅ Model evaluated, MAE: {round(mae, 2)}")

    return metrics
