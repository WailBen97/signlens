{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c24e262e-0a00-4aa8-8818-38c260b2f404",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:43:13.722379Z",
     "iopub.status.busy": "2024-03-24T10:43:13.721980Z",
     "iopub.status.idle": "2024-03-24T10:43:17.755947Z",
     "shell.execute_reply": "2024-03-24T10:43:17.754824Z",
     "shell.execute_reply.started": "2024-03-24T10:43:13.722353Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 11:43:15.121075: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-24 11:43:16.212272: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import model_utils\n",
    "\n",
    "from signlens.params import *\n",
    "from signlens.preprocessing.data import load_data_subset_csv, load_glossary, load_video_list_json, load_landmarks_json\n",
    "from signlens.preprocessing.preprocess import group_pad_sequences, encode_labels, decode_labels, pad_and_preprocess_sequence, reshape_processed_data_to_tf\n",
    "from utils.model_utils import load_model\n",
    "from utils.video_utils import process_video_to_landmarks_json, draw_landmarks_on_image\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11a3fdeb-cc5a-4656-9ca2-155cc84d07ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:43:17.758451Z",
     "iopub.status.busy": "2024-03-24T10:43:17.757790Z",
     "iopub.status.idle": "2024-03-24T10:43:17.844323Z",
     "shell.execute_reply": "2024-03-24T10:43:17.843410Z",
     "shell.execute_reply.started": "2024-03-24T10:43:17.758406Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLoading data subset from train_test.csv\u001b[0m\n",
      "    ℹ️ Filtered sequences with missing frames. Size reduced from 17233 to 17233 (100.00%)\n",
      "    ℹ️ Filtered on n_frames = 100. Size reduced from 17233 to 17233 (100.00%)\n",
      "    ℹ️ Filtered on n_classes = 10. Size reduced from 17233 to 690 (4.00%)\n",
      "    ℹ️ Balanced data, with average of 34.5 elements per class. Size reduced from 690 to 345 (50.00%)\n",
      "✅ Loaded 345 rows (2.00% of the original 17233 rows) from the dataset.\n"
     ]
    }
   ],
   "source": [
    "test_data = load_data_subset_csv(balanced=True, csv_path=TRAIN_TEST_CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdef6b21-48d8-4416-b643-77e5ada9c227",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:43:17.845728Z",
     "iopub.status.busy": "2024-03-24T10:43:17.845430Z",
     "iopub.status.idle": "2024-03-24T10:43:17.903568Z",
     "shell.execute_reply": "2024-03-24T10:43:17.902181Z",
     "shell.execute_reply.started": "2024-03-24T10:43:17.845699Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "      <th>n_frames</th>\n",
       "      <th>n_frames2</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmark_files_noface/29302/2142576162.p...</td>\n",
       "      <td>29302</td>\n",
       "      <td>2142576162</td>\n",
       "      <td>who</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmark_files_noface/4718/759445081.par...</td>\n",
       "      <td>4718</td>\n",
       "      <td>759445081</td>\n",
       "      <td>go</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmark_files_noface/32319/891170574.pa...</td>\n",
       "      <td>32319</td>\n",
       "      <td>891170574</td>\n",
       "      <td>go</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmark_files_noface/2044/499025251.par...</td>\n",
       "      <td>2044</td>\n",
       "      <td>499025251</td>\n",
       "      <td>chair</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmark_files_noface/32319/2378796814.p...</td>\n",
       "      <td>32319</td>\n",
       "      <td>2378796814</td>\n",
       "      <td>no</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>train_landmark_files_noface/29302/1238194975.p...</td>\n",
       "      <td>29302</td>\n",
       "      <td>1238194975</td>\n",
       "      <td>all</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>train_landmark_files_noface/37055/3598511182.p...</td>\n",
       "      <td>37055</td>\n",
       "      <td>3598511182</td>\n",
       "      <td>before</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>train_landmark_files_noface/2044/3196736964.pa...</td>\n",
       "      <td>2044</td>\n",
       "      <td>3196736964</td>\n",
       "      <td>yes</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>train_landmark_files_noface/62590/1083816707.p...</td>\n",
       "      <td>62590</td>\n",
       "      <td>1083816707</td>\n",
       "      <td>go</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>train_landmark_files_noface/49445/1857934386.p...</td>\n",
       "      <td>49445</td>\n",
       "      <td>1857934386</td>\n",
       "      <td>no</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path  participant_id  \\\n",
       "0    train_landmark_files_noface/29302/2142576162.p...           29302   \n",
       "1    train_landmark_files_noface/4718/759445081.par...            4718   \n",
       "2    train_landmark_files_noface/32319/891170574.pa...           32319   \n",
       "3    train_landmark_files_noface/2044/499025251.par...            2044   \n",
       "4    train_landmark_files_noface/32319/2378796814.p...           32319   \n",
       "..                                                 ...             ...   \n",
       "340  train_landmark_files_noface/29302/1238194975.p...           29302   \n",
       "341  train_landmark_files_noface/37055/3598511182.p...           37055   \n",
       "342  train_landmark_files_noface/2044/3196736964.pa...            2044   \n",
       "343  train_landmark_files_noface/62590/1083816707.p...           62590   \n",
       "344  train_landmark_files_noface/49445/1857934386.p...           49445   \n",
       "\n",
       "     sequence_id    sign  n_frames  n_frames2  \\\n",
       "0     2142576162     who        26         26   \n",
       "1      759445081      go         2          2   \n",
       "2      891170574      go        16         16   \n",
       "3      499025251   chair        15         15   \n",
       "4     2378796814      no        88         88   \n",
       "..           ...     ...       ...        ...   \n",
       "340   1238194975     all        47         47   \n",
       "341   3598511182  before        51         51   \n",
       "342   3196736964     yes        17         17   \n",
       "343   1083816707      go        16         16   \n",
       "344   1857934386      no        33         33   \n",
       "\n",
       "                                             file_path  \n",
       "0    /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "1    /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "2    /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "3    /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "4    /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "..                                                 ...  \n",
       "340  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "341  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "342  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "343  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "344  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "\n",
       "[345 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58b5508-1619-4866-8b1d-583a27b1af6a",
   "metadata": {},
   "source": [
    "# Model predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2036b32-be2d-4273-a0d0-77e211e06ad6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:43:17.905329Z",
     "iopub.status.busy": "2024-03-24T10:43:17.904994Z",
     "iopub.status.idle": "2024-03-24T10:43:19.829136Z",
     "shell.execute_reply": "2024-03-24T10:43:19.827552Z",
     "shell.execute_reply.started": "2024-03-24T10:43:17.905296Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Load latest model from local registry...\u001b[0m\n",
      "\u001b[34m\n",
      "Load latest model from disk...\u001b[0m\n",
      "✅ Model loaded from local disk /home/bfrisque/code/benoitfrisque/signlens/training_outputs/model 20240322-173411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 11:43:19.145897: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-24 11:43:19.146263: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/bfrisque/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['book', 'before'], array([0.15544349, 0.13411503], dtype=float32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"model 20240322-173411\"\n",
    "model, _ = load_model(model_name)\n",
    "\n",
    "processed_data = group_pad_sequences(test_data.file_path.iloc[0:2])\n",
    "\n",
    "prediction = model.predict([processed_data])\n",
    "\n",
    "word, proba = decode_labels(prediction)\n",
    "\n",
    "word, proba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17edf13e-a193-49cd-aaee-1a4058849bf1",
   "metadata": {},
   "source": [
    "# Video conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a92007ce-a863-4520-9e22-9cf1632dbdf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:43:19.832534Z",
     "iopub.status.busy": "2024-03-24T10:43:19.831799Z",
     "iopub.status.idle": "2024-03-24T10:43:20.679626Z",
     "shell.execute_reply": "2024-03-24T10:43:20.678102Z",
     "shell.execute_reply.started": "2024-03-24T10:43:19.832487Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sign</th>\n",
       "      <th>bbox</th>\n",
       "      <th>fps</th>\n",
       "      <th>frame_end</th>\n",
       "      <th>frame_start</th>\n",
       "      <th>instance_id</th>\n",
       "      <th>signer_id</th>\n",
       "      <th>source</th>\n",
       "      <th>split</th>\n",
       "      <th>url</th>\n",
       "      <th>variation_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airplane</td>\n",
       "      <td>[605, 21, 1721, 1076]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>signschool</td>\n",
       "      <td>train</td>\n",
       "      <td>https://signstock.blob.core.windows.net/signsc...</td>\n",
       "      <td>0</td>\n",
       "      <td>01726</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>table</td>\n",
       "      <td>[374, 52, 810, 720]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>startasl</td>\n",
       "      <td>train</td>\n",
       "      <td>https://s3-us-west-1.amazonaws.com/files.start...</td>\n",
       "      <td>0</td>\n",
       "      <td>56556</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>see</td>\n",
       "      <td>[85, 15, 230, 192]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>signingsavvy</td>\n",
       "      <td>train</td>\n",
       "      <td>https://www.signingsavvy.com/signs/mp4/8/8396.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>50125</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who</td>\n",
       "      <td>[165, 4, 472, 370]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>88</td>\n",
       "      <td>aslsignbank</td>\n",
       "      <td>train</td>\n",
       "      <td>https://aslsignbank.haskins.yale.edu/dictionar...</td>\n",
       "      <td>0</td>\n",
       "      <td>66778</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dog</td>\n",
       "      <td>[417, 61, 834, 720]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>startasl</td>\n",
       "      <td>train</td>\n",
       "      <td>https://s3-us-west-1.amazonaws.com/files.start...</td>\n",
       "      <td>1</td>\n",
       "      <td>17086</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>arm</td>\n",
       "      <td>[205, 37, 489, 370]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "      <td>aslsignbank</td>\n",
       "      <td>val</td>\n",
       "      <td>https://aslsignbank.haskins.yale.edu/dictionar...</td>\n",
       "      <td>0</td>\n",
       "      <td>65094</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>say</td>\n",
       "      <td>[104, 0, 528, 480]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>asldeafined</td>\n",
       "      <td>val</td>\n",
       "      <td>https://media.asldeafined.com/vocabulary/14687...</td>\n",
       "      <td>0</td>\n",
       "      <td>49430</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>ear</td>\n",
       "      <td>[296, 36, 879, 720]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>aslbrick</td>\n",
       "      <td>train</td>\n",
       "      <td>http://aslbricks.org/New/ASL-Videos/ear.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>69306</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>closet</td>\n",
       "      <td>[64, 14, 260, 240]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>spreadthesign</td>\n",
       "      <td>train</td>\n",
       "      <td>https://media.spreadthesign.com/video/mp4/13/3...</td>\n",
       "      <td>0</td>\n",
       "      <td>11284</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>airplane</td>\n",
       "      <td>[101, 23, 503, 480]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>asldeafined</td>\n",
       "      <td>train</td>\n",
       "      <td>https://media.asldeafined.com/vocabulary/14661...</td>\n",
       "      <td>0</td>\n",
       "      <td>01727</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1476 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sign                   bbox  fps  frame_end  frame_start  \\\n",
       "0     airplane  [605, 21, 1721, 1076]   25         -1            1   \n",
       "1        table    [374, 52, 810, 720]   25         -1            1   \n",
       "2          see     [85, 15, 230, 192]   25         -1            1   \n",
       "3          who     [165, 4, 472, 370]   25         -1            1   \n",
       "4          dog    [417, 61, 834, 720]   25         -1            1   \n",
       "...        ...                    ...  ...        ...          ...   \n",
       "1471       arm    [205, 37, 489, 370]   25         -1            1   \n",
       "1472       say     [104, 0, 528, 480]   25         -1            1   \n",
       "1473       ear    [296, 36, 879, 720]   25         -1            1   \n",
       "1474    closet     [64, 14, 260, 240]   25         -1            1   \n",
       "1475  airplane    [101, 23, 503, 480]   25         -1            1   \n",
       "\n",
       "      instance_id  signer_id         source  split  \\\n",
       "0              10          4     signschool  train   \n",
       "1              13         38       startasl  train   \n",
       "2               8         11   signingsavvy  train   \n",
       "3              14         88    aslsignbank  train   \n",
       "4               7         38       startasl  train   \n",
       "...           ...        ...            ...    ...   \n",
       "1471            3         89    aslsignbank    val   \n",
       "1472            4         13    asldeafined    val   \n",
       "1473            1        118       aslbrick  train   \n",
       "1474            6         26  spreadthesign  train   \n",
       "1475           11         13    asldeafined  train   \n",
       "\n",
       "                                                    url  variation_id  \\\n",
       "0     https://signstock.blob.core.windows.net/signsc...             0   \n",
       "1     https://s3-us-west-1.amazonaws.com/files.start...             0   \n",
       "2     https://www.signingsavvy.com/signs/mp4/8/8396.mp4             0   \n",
       "3     https://aslsignbank.haskins.yale.edu/dictionar...             0   \n",
       "4     https://s3-us-west-1.amazonaws.com/files.start...             1   \n",
       "...                                                 ...           ...   \n",
       "1471  https://aslsignbank.haskins.yale.edu/dictionar...             0   \n",
       "1472  https://media.asldeafined.com/vocabulary/14687...             0   \n",
       "1473        http://aslbricks.org/New/ASL-Videos/ear.mp4             0   \n",
       "1474  https://media.spreadthesign.com/video/mp4/13/3...             0   \n",
       "1475  https://media.asldeafined.com/vocabulary/14661...             0   \n",
       "\n",
       "     video_id                                         video_path  \n",
       "0       01726  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "1       56556  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "2       50125  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "3       66778  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "4       17086  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "...       ...                                                ...  \n",
       "1471    65094  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "1472    49430  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "1473    69306  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "1474    11284  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "1475    01727  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "\n",
       "[1476 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos = load_video_list_json()\n",
    "videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3793e3a6-52ba-44be-9278-a4b382cc27e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:43:20.681196Z",
     "iopub.status.busy": "2024-03-24T10:43:20.680899Z",
     "iopub.status.idle": "2024-03-24T10:43:20.725798Z",
     "shell.execute_reply": "2024-03-24T10:43:20.722740Z",
     "shell.execute_reply.started": "2024-03-24T10:43:20.681167Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bfrisque/code/benoitfrisque/signlens/raw_data/WLASL/videos/07070.mp4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path = videos[videos.sign == 'book'].video_path.iloc[0]\n",
    "video_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d29e093-ff99-4c12-ae6f-1d360f0c1925",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:43:20.732074Z",
     "iopub.status.busy": "2024-03-24T10:43:20.730926Z",
     "iopub.status.idle": "2024-03-24T10:43:26.822013Z",
     "shell.execute_reply": "2024-03-24T10:43:26.820674Z",
     "shell.execute_reply.started": "2024-03-24T10:43:20.732032Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Landmarks saved to '/home/bfrisque/code/benoitfrisque/signlens/processed_data/landmarks_videos/landmarks_07070.json'\n"
     ]
    }
   ],
   "source": [
    "json_data = process_video_to_landmarks_json(video_path, output=True, frame_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a750b6fe-192d-4497-9543-53044c9f77fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:43:26.823683Z",
     "iopub.status.busy": "2024-03-24T10:43:26.823219Z",
     "iopub.status.idle": "2024-03-24T10:43:26.904016Z",
     "shell.execute_reply": "2024-03-24T10:43:26.902218Z",
     "shell.execute_reply.started": "2024-03-24T10:43:26.823644Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 100, 225])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks_json_path = '/home/bfrisque/code/benoitfrisque/signlens/processed_data/landmarks_videos/landmarks_07070.json'\n",
    "\n",
    "landmarks = load_landmarks_json(landmarks_json_path)\n",
    "data_processed = pad_and_preprocess_sequence(landmarks)\n",
    "data_tf = reshape_processed_data_to_tf(data_processed)\n",
    "data_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35e097c4-d7af-497e-8454-d5f3ee0adc2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:43:26.905757Z",
     "iopub.status.busy": "2024-03-24T10:43:26.905377Z",
     "iopub.status.idle": "2024-03-24T10:43:27.439106Z",
     "shell.execute_reply": "2024-03-24T10:43:27.437821Z",
     "shell.execute_reply.started": "2024-03-24T10:43:26.905723Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Load latest model from local registry...\u001b[0m\n",
      "\u001b[34m\n",
      "Load latest model from disk...\u001b[0m\n",
      "✅ Model loaded from local disk /home/bfrisque/code/benoitfrisque/signlens/training_outputs/model 20240322-173411\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['who'], array([0.16311456], dtype=float32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"model 20240322-173411\"\n",
    "model, _ = load_model(model_name)\n",
    "\n",
    "prediction = model.predict(data_tf)\n",
    "\n",
    "word, proba = decode_labels(prediction)\n",
    "\n",
    "word, proba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7784b43a-f879-49ec-846e-4dd2e21f240a",
   "metadata": {},
   "source": [
    "## Write landmarks on video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398cc2d3-21b9-4fca-8d52-c46632899410",
   "metadata": {},
   "source": [
    "### New version of mediapipe - hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "813a2322-d96b-4efd-8f20-2cb8f1d58913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:43:27.441489Z",
     "iopub.status.busy": "2024-03-24T10:43:27.440737Z",
     "iopub.status.idle": "2024-03-24T10:43:27.484607Z",
     "shell.execute_reply": "2024-03-24T10:43:27.482240Z",
     "shell.execute_reply.started": "2024-03-24T10:43:27.441455Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# video_path = videos[videos.sign == 'book'].video_path.iloc[0]\n",
    "# video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40c748ce-b05d-4c01-809d-816dc5368732",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:43:27.486505Z",
     "iopub.status.busy": "2024-03-24T10:43:27.486092Z",
     "iopub.status.idle": "2024-03-24T10:43:27.529262Z",
     "shell.execute_reply": "2024-03-24T10:43:27.527962Z",
     "shell.execute_reply.started": "2024-03-24T10:43:27.486472Z"
    }
   },
   "outputs": [],
   "source": [
    "# !wget -q https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4456064-63cb-43ab-ab4f-53b97e1a3b38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:43:27.530896Z",
     "iopub.status.busy": "2024-03-24T10:43:27.530572Z",
     "iopub.status.idle": "2024-03-24T10:43:27.582762Z",
     "shell.execute_reply": "2024-03-24T10:43:27.581686Z",
     "shell.execute_reply.started": "2024-03-24T10:43:27.530865Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #@markdown We implemented some functions to visualize the hand landmark detection results. <br/> Run the following cell to activate the functions.\n",
    "\n",
    "# from mediapipe import solutions\n",
    "# from mediapipe.framework.formats import landmark_pb2\n",
    "# import numpy as np\n",
    "\n",
    "# MARGIN = 10  # pixels\n",
    "# FONT_SIZE = 1\n",
    "# FONT_THICKNESS = 1\n",
    "# HANDEDNESS_TEXT_COLOR = (88, 205, 54) # vibrant green\n",
    "\n",
    "# def draw_landmarks_on_image_new(rgb_image, detection_result):\n",
    "#   hand_landmarks_list = detection_result.hand_landmarks\n",
    "#   handedness_list = detection_result.handedness\n",
    "#   annotated_image = np.copy(rgb_image)\n",
    "\n",
    "#   # Loop through the detected hands to visualize.\n",
    "#   for idx in range(len(hand_landmarks_list)):\n",
    "#     hand_landmarks = hand_landmarks_list[idx]\n",
    "#     handedness = handedness_list[idx]\n",
    "\n",
    "#     # Draw the hand landmarks.\n",
    "#     hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "#     hand_landmarks_proto.landmark.extend([\n",
    "#       landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in hand_landmarks\n",
    "#     ])\n",
    "    \n",
    "#     solutions.drawing_utils.draw_landmarks(\n",
    "#       annotated_image,\n",
    "#       hand_landmarks_proto,\n",
    "#       solutions.hands.HAND_CONNECTIONS,\n",
    "#       solutions.drawing_styles.get_default_hand_landmarks_style(),\n",
    "#       solutions.drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "#     # Get the top left corner of the detected hand's bounding box.\n",
    "#     height, width, _ = annotated_image.shape\n",
    "#     x_coordinates = [landmark.x for landmark in hand_landmarks]\n",
    "#     y_coordinates = [landmark.y for landmark in hand_landmarks]\n",
    "#     text_x = int(min(x_coordinates) * width)\n",
    "#     text_y = int(min(y_coordinates) * height) - MARGIN\n",
    "\n",
    "#     # Draw handedness (left or right hand) on the image.\n",
    "#     cv2.putText(annotated_image, f\"{handedness[0].category_name}\",\n",
    "#                 (text_x, text_y), cv2.FONT_HERSHEY_DUPLEX,\n",
    "#                 FONT_SIZE, HANDEDNESS_TEXT_COLOR, FONT_THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "#   return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e37490a-974f-4123-a246-6f58a6400ed0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:43:27.585301Z",
     "iopub.status.busy": "2024-03-24T10:43:27.584800Z",
     "iopub.status.idle": "2024-03-24T10:43:27.631432Z",
     "shell.execute_reply": "2024-03-24T10:43:27.630055Z",
     "shell.execute_reply.started": "2024-03-24T10:43:27.585251Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import mediapipe as mp\n",
    "# from mediapipe import solutions\n",
    "# from mediapipe.framework.formats import landmark_pb2\n",
    "# from mediapipe.tasks import python\n",
    "# from mediapipe.tasks.python import vision\n",
    "\n",
    "# base_options = python.BaseOptions(model_asset_path='hand_landmarker.task')\n",
    "# running_mode =  vision.RunningMode('VIDEO')\n",
    "# options = vision.HandLandmarkerOptions(base_options=base_options,\n",
    "#                                        num_hands=2)\n",
    "# detector = vision.HandLandmarker.create_from_options(options)\n",
    "\n",
    "# cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# # Load the frame rate of the video using OpenCV's CAP_PROP_FPS\n",
    "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "    \n",
    "#     # Convert the frame to RGB\n",
    "#     rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "#     # Convert the frame to MediaPipe's Image object\n",
    "#     image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
    "    \n",
    "#     # Get the timestamp for the current frame\n",
    "#     frame_timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "\n",
    "#         # STEP 4: Detect hand landmarks from the input image.\n",
    "#     detection_result = detector.detect(image)\n",
    "\n",
    "#     # # STEP 5: Process the classification result. In this case, visualize it.\n",
    "#     annotated_image = draw_landmarks_on_image_new(image.numpy_view(), detection_result)\n",
    "#     annotated_image_color = cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#     cv2.imshow('Annotated Image', annotated_image_color)\n",
    "   \n",
    "    \n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#          break\n",
    "\n",
    "# # Release the video capture object and close all windows\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8118470a-ecbc-4105-a3b5-e14c9804d322",
   "metadata": {},
   "source": [
    "# Old version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7b9c243-1f4e-4660-8f8f-2fa2b23ae943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:59:20.872787Z",
     "iopub.status.busy": "2024-03-24T10:59:20.872372Z",
     "iopub.status.idle": "2024-03-24T10:59:26.851342Z",
     "shell.execute_reply": "2024-03-24T10:59:26.849908Z",
     "shell.execute_reply.started": "2024-03-24T10:59:20.872759Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Landmarks saved to '/home/bfrisque/code/benoitfrisque/signlens/processed_data/landmarks_videos/landmarks_07070.json'\n"
     ]
    }
   ],
   "source": [
    "json_data = process_video_to_landmarks_json(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3625a315-926e-4f4e-a957-d904e8519614",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:43:35.287996Z",
     "iopub.status.busy": "2024-03-24T10:43:35.287717Z",
     "iopub.status.idle": "2024-03-24T10:43:41.684369Z",
     "shell.execute_reply": "2024-03-24T10:43:41.683160Z",
     "shell.execute_reply.started": "2024-03-24T10:43:35.287968Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Load the frame rate of the video using OpenCV's CAP_PROP_FPS\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "with mp_holistic.Holistic(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "         # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(image)\n",
    "        \n",
    "     # Draw landmark annotation on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            results.face_landmarks,\n",
    "            mp_holistic.FACEMESH_CONTOURS,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles\n",
    "            .get_default_face_mesh_contours_style())\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            results.pose_landmarks,\n",
    "            mp_holistic.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing_styles\n",
    "            .get_default_pose_landmarks_style())\n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        cv2.imshow('MediaPipe Holistic', cv2.flip(image, 1))\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "          break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "   \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d825348f-e640-4956-934a-e7d5be8b31ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
