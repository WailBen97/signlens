{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c24e262e-0a00-4aa8-8818-38c260b2f404",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T15:42:27.538349Z",
     "iopub.status.busy": "2024-03-26T15:42:27.537555Z",
     "iopub.status.idle": "2024-03-26T15:42:28.608281Z",
     "shell.execute_reply": "2024-03-26T15:42:28.605276Z",
     "shell.execute_reply.started": "2024-03-26T15:42:27.538307Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'model_utils' from 'utils' (/home/bfrisque/code/benoitfrisque/signlens/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_utils\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msignlens\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparams\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msignlens\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_data_subset_csv, load_glossary, load_video_list_json, load_landmarks_json\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'model_utils' from 'utils' (/home/bfrisque/code/benoitfrisque/signlens/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import model_utils\n",
    "\n",
    "from signlens.params import *\n",
    "from signlens.preprocessing.data import load_data_subset_csv, load_glossary, load_video_list_json, load_landmarks_json\n",
    "from signlens.preprocessing.preprocess import group_pad_sequences, encode_labels, decode_labels, pad_and_preprocess_sequence, reshape_processed_data_to_tf\n",
    "from utils.model_utils import load_model\n",
    "from utils.video_utils import process_video_to_landmarks_json, draw_landmarks_on_image\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a3fdeb-cc5a-4656-9ca2-155cc84d07ad",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-25T08:12:42.787210Z",
     "iopub.status.idle": "2024-03-25T08:12:42.787731Z",
     "shell.execute_reply": "2024-03-25T08:12:42.787511Z",
     "shell.execute_reply.started": "2024-03-25T08:12:42.787483Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = load_data_subset_csv(balanced=True, csv_path=TRAIN_TEST_CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdef6b21-48d8-4416-b643-77e5ada9c227",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-25T08:12:42.790505Z",
     "iopub.status.idle": "2024-03-25T08:12:42.791054Z",
     "shell.execute_reply": "2024-03-25T08:12:42.790828Z",
     "shell.execute_reply.started": "2024-03-25T08:12:42.790801Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58b5508-1619-4866-8b1d-583a27b1af6a",
   "metadata": {},
   "source": [
    "# Model predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2036b32-be2d-4273-a0d0-77e211e06ad6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:38:05.765641Z",
     "iopub.status.busy": "2024-03-24T12:38:05.765374Z",
     "iopub.status.idle": "2024-03-24T12:38:07.666730Z",
     "shell.execute_reply": "2024-03-24T12:38:07.665624Z",
     "shell.execute_reply.started": "2024-03-24T12:38:05.765614Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Load latest model from local registry...\u001b[0m\n",
      "\u001b[34m\n",
      "Load latest model from disk...\u001b[0m\n",
      "✅ Model loaded from local disk /home/bfrisque/code/benoitfrisque/signlens/training_outputs/model 20240322-173411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 13:38:06.985278: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-24 13:38:06.985744: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/bfrisque/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['who', 'who'], array([0.45869172, 0.20116639], dtype=float32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"model 20240322-173411\"\n",
    "model, _ = load_model(model_name)\n",
    "\n",
    "processed_data = preprocess_and_pad_sequences_from_pq_list(test_data.file_path.iloc[0:2])\n",
    "\n",
    "prediction = model.predict([processed_data])\n",
    "\n",
    "word, proba = decode_labels(prediction)\n",
    "\n",
    "word, proba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17edf13e-a193-49cd-aaee-1a4058849bf1",
   "metadata": {},
   "source": [
    "# Video conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a92007ce-a863-4520-9e22-9cf1632dbdf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T08:13:36.949860Z",
     "iopub.status.busy": "2024-03-25T08:13:36.948060Z",
     "iopub.status.idle": "2024-03-25T08:13:40.050399Z",
     "shell.execute_reply": "2024-03-25T08:13:40.043699Z",
     "shell.execute_reply.started": "2024-03-25T08:13:36.949794Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sign</th>\n",
       "      <th>bbox</th>\n",
       "      <th>fps</th>\n",
       "      <th>frame_end</th>\n",
       "      <th>frame_start</th>\n",
       "      <th>instance_id</th>\n",
       "      <th>signer_id</th>\n",
       "      <th>source</th>\n",
       "      <th>split</th>\n",
       "      <th>url</th>\n",
       "      <th>variation_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airplane</td>\n",
       "      <td>[605, 21, 1721, 1076]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>signschool</td>\n",
       "      <td>train</td>\n",
       "      <td>https://signstock.blob.core.windows.net/signsc...</td>\n",
       "      <td>0</td>\n",
       "      <td>01726</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>table</td>\n",
       "      <td>[374, 52, 810, 720]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>startasl</td>\n",
       "      <td>train</td>\n",
       "      <td>https://s3-us-west-1.amazonaws.com/files.start...</td>\n",
       "      <td>0</td>\n",
       "      <td>56556</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>see</td>\n",
       "      <td>[85, 15, 230, 192]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>signingsavvy</td>\n",
       "      <td>train</td>\n",
       "      <td>https://www.signingsavvy.com/signs/mp4/8/8396.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>50125</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who</td>\n",
       "      <td>[165, 4, 472, 370]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>88</td>\n",
       "      <td>aslsignbank</td>\n",
       "      <td>train</td>\n",
       "      <td>https://aslsignbank.haskins.yale.edu/dictionar...</td>\n",
       "      <td>0</td>\n",
       "      <td>66778</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dog</td>\n",
       "      <td>[417, 61, 834, 720]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>startasl</td>\n",
       "      <td>train</td>\n",
       "      <td>https://s3-us-west-1.amazonaws.com/files.start...</td>\n",
       "      <td>1</td>\n",
       "      <td>17086</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>arm</td>\n",
       "      <td>[205, 37, 489, 370]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "      <td>aslsignbank</td>\n",
       "      <td>val</td>\n",
       "      <td>https://aslsignbank.haskins.yale.edu/dictionar...</td>\n",
       "      <td>0</td>\n",
       "      <td>65094</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>say</td>\n",
       "      <td>[104, 0, 528, 480]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>asldeafined</td>\n",
       "      <td>val</td>\n",
       "      <td>https://media.asldeafined.com/vocabulary/14687...</td>\n",
       "      <td>0</td>\n",
       "      <td>49430</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>ear</td>\n",
       "      <td>[296, 36, 879, 720]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>aslbrick</td>\n",
       "      <td>train</td>\n",
       "      <td>http://aslbricks.org/New/ASL-Videos/ear.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>69306</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>closet</td>\n",
       "      <td>[64, 14, 260, 240]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>spreadthesign</td>\n",
       "      <td>train</td>\n",
       "      <td>https://media.spreadthesign.com/video/mp4/13/3...</td>\n",
       "      <td>0</td>\n",
       "      <td>11284</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>airplane</td>\n",
       "      <td>[101, 23, 503, 480]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>asldeafined</td>\n",
       "      <td>train</td>\n",
       "      <td>https://media.asldeafined.com/vocabulary/14661...</td>\n",
       "      <td>0</td>\n",
       "      <td>01727</td>\n",
       "      <td>/home/bfrisque/code/benoitfrisque/signlens/raw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1476 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sign                   bbox  fps  frame_end  frame_start  \\\n",
       "0     airplane  [605, 21, 1721, 1076]   25         -1            1   \n",
       "1        table    [374, 52, 810, 720]   25         -1            1   \n",
       "2          see     [85, 15, 230, 192]   25         -1            1   \n",
       "3          who     [165, 4, 472, 370]   25         -1            1   \n",
       "4          dog    [417, 61, 834, 720]   25         -1            1   \n",
       "...        ...                    ...  ...        ...          ...   \n",
       "1471       arm    [205, 37, 489, 370]   25         -1            1   \n",
       "1472       say     [104, 0, 528, 480]   25         -1            1   \n",
       "1473       ear    [296, 36, 879, 720]   25         -1            1   \n",
       "1474    closet     [64, 14, 260, 240]   25         -1            1   \n",
       "1475  airplane    [101, 23, 503, 480]   25         -1            1   \n",
       "\n",
       "      instance_id  signer_id         source  split  \\\n",
       "0              10          4     signschool  train   \n",
       "1              13         38       startasl  train   \n",
       "2               8         11   signingsavvy  train   \n",
       "3              14         88    aslsignbank  train   \n",
       "4               7         38       startasl  train   \n",
       "...           ...        ...            ...    ...   \n",
       "1471            3         89    aslsignbank    val   \n",
       "1472            4         13    asldeafined    val   \n",
       "1473            1        118       aslbrick  train   \n",
       "1474            6         26  spreadthesign  train   \n",
       "1475           11         13    asldeafined  train   \n",
       "\n",
       "                                                    url  variation_id  \\\n",
       "0     https://signstock.blob.core.windows.net/signsc...             0   \n",
       "1     https://s3-us-west-1.amazonaws.com/files.start...             0   \n",
       "2     https://www.signingsavvy.com/signs/mp4/8/8396.mp4             0   \n",
       "3     https://aslsignbank.haskins.yale.edu/dictionar...             0   \n",
       "4     https://s3-us-west-1.amazonaws.com/files.start...             1   \n",
       "...                                                 ...           ...   \n",
       "1471  https://aslsignbank.haskins.yale.edu/dictionar...             0   \n",
       "1472  https://media.asldeafined.com/vocabulary/14687...             0   \n",
       "1473        http://aslbricks.org/New/ASL-Videos/ear.mp4             0   \n",
       "1474  https://media.spreadthesign.com/video/mp4/13/3...             0   \n",
       "1475  https://media.asldeafined.com/vocabulary/14661...             0   \n",
       "\n",
       "     video_id                                         video_path  \n",
       "0       01726  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "1       56556  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "2       50125  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "3       66778  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "4       17086  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "...       ...                                                ...  \n",
       "1471    65094  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "1472    49430  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "1473    69306  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "1474    11284  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "1475    01727  /home/bfrisque/code/benoitfrisque/signlens/raw...  \n",
       "\n",
       "[1476 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos = load_video_list_json()\n",
    "videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3793e3a6-52ba-44be-9278-a4b382cc27e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T08:13:46.057875Z",
     "iopub.status.busy": "2024-03-25T08:13:46.056236Z",
     "iopub.status.idle": "2024-03-25T08:13:46.079734Z",
     "shell.execute_reply": "2024-03-25T08:13:46.077640Z",
     "shell.execute_reply.started": "2024-03-25T08:13:46.057818Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bfrisque/code/benoitfrisque/signlens/raw_data/WLASL/videos/07070.mp4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path = videos[videos.sign == 'book'].video_path.iloc[0]\n",
    "video_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d29e093-ff99-4c12-ae6f-1d360f0c1925",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T08:14:01.410291Z",
     "iopub.status.busy": "2024-03-25T08:14:01.409718Z",
     "iopub.status.idle": "2024-03-25T08:14:01.484178Z",
     "shell.execute_reply": "2024-03-25T08:14:01.480504Z",
     "shell.execute_reply.started": "2024-03-25T08:14:01.410227Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_video_to_landmarks_json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m json_data \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_video_to_landmarks_json\u001b[49m(video_path, json_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, show_preview\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, frame_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'process_video_to_landmarks_json' is not defined"
     ]
    }
   ],
   "source": [
    "json_data = process_video_to_landmarks_json(video_path, json_output=True, show_preview=False, frame_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a750b6fe-192d-4497-9543-53044c9f77fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:38:13.754424Z",
     "iopub.status.busy": "2024-03-24T12:38:13.753556Z",
     "iopub.status.idle": "2024-03-24T12:38:13.823665Z",
     "shell.execute_reply": "2024-03-24T12:38:13.822272Z",
     "shell.execute_reply.started": "2024-03-24T12:38:13.754396Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 100, 225])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks_json_path = '/home/bfrisque/code/benoitfrisque/signlens/processed_data/landmarks_videos/07070_landmarks.json'\n",
    "\n",
    "landmarks = load_landmarks_json(landmarks_json_path)\n",
    "data_processed = pad_and_preprocess_sequence(landmarks)\n",
    "data_tf = reshape_processed_data_to_tf(data_processed)\n",
    "data_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35e097c4-d7af-497e-8454-d5f3ee0adc2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:38:13.825578Z",
     "iopub.status.busy": "2024-03-24T12:38:13.824956Z",
     "iopub.status.idle": "2024-03-24T12:38:14.246088Z",
     "shell.execute_reply": "2024-03-24T12:38:14.244974Z",
     "shell.execute_reply.started": "2024-03-24T12:38:13.825544Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Load latest model from local registry...\u001b[0m\n",
      "\u001b[34m\n",
      "Load latest model from disk...\u001b[0m\n",
      "✅ Model loaded from local disk /home/bfrisque/code/benoitfrisque/signlens/training_outputs/model 20240322-173411\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['fine'], array([0.15782131], dtype=float32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"model 20240322-173411\"\n",
    "model, _ = load_model(model_name)\n",
    "\n",
    "prediction = model.predict(data_tf)\n",
    "\n",
    "word, proba = decode_labels(prediction)\n",
    "\n",
    "word, proba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7784b43a-f879-49ec-846e-4dd2e21f240a",
   "metadata": {},
   "source": [
    "## Write landmarks on video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8118470a-ecbc-4105-a3b5-e14c9804d322",
   "metadata": {},
   "source": [
    "### Previous version of mediapipe (used in this project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7b9c243-1f4e-4660-8f8f-2fa2b23ae943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:38:14.248206Z",
     "iopub.status.busy": "2024-03-24T12:38:14.247311Z",
     "iopub.status.idle": "2024-03-24T12:38:20.279042Z",
     "shell.execute_reply": "2024-03-24T12:38:20.277734Z",
     "shell.execute_reply.started": "2024-03-24T12:38:14.248162Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Landmarks saved to '/home/bfrisque/code/benoitfrisque/signlens/processed_data/landmarks_videos/07070_landmarks.json'\n",
      "✅ Annotated video saved to '/home/bfrisque/code/benoitfrisque/signlens/processed_data/landmarks_videos/07070_annotated.mp4'\n"
     ]
    }
   ],
   "source": [
    "json_data = process_video_to_landmarks_json(video_path, show_preview=True, save_annotated_video=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398cc2d3-21b9-4fca-8d52-c46632899410",
   "metadata": {},
   "source": [
    "### New version of mediapipe - hand (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40c748ce-b05d-4c01-809d-816dc5368732",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:38:20.283030Z",
     "iopub.status.busy": "2024-03-24T12:38:20.281319Z",
     "iopub.status.idle": "2024-03-24T12:38:20.325121Z",
     "shell.execute_reply": "2024-03-24T12:38:20.324122Z",
     "shell.execute_reply.started": "2024-03-24T12:38:20.282980Z"
    }
   },
   "outputs": [],
   "source": [
    "# !wget -q https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4456064-63cb-43ab-ab4f-53b97e1a3b38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:38:20.326846Z",
     "iopub.status.busy": "2024-03-24T12:38:20.326358Z",
     "iopub.status.idle": "2024-03-24T12:38:20.368568Z",
     "shell.execute_reply": "2024-03-24T12:38:20.367505Z",
     "shell.execute_reply.started": "2024-03-24T12:38:20.326818Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #@markdown We implemented some functions to visualize the hand landmark detection results. <br/> Run the following cell to activate the functions.\n",
    "\n",
    "# from mediapipe import solutions\n",
    "# from mediapipe.framework.formats import landmark_pb2\n",
    "# import numpy as np\n",
    "\n",
    "# MARGIN = 10  # pixels\n",
    "# FONT_SIZE = 1\n",
    "# FONT_THICKNESS = 1\n",
    "# HANDEDNESS_TEXT_COLOR = (88, 205, 54) # vibrant green\n",
    "\n",
    "# def draw_landmarks_on_image_new(rgb_image, detection_result):\n",
    "#   hand_landmarks_list = detection_result.hand_landmarks\n",
    "#   handedness_list = detection_result.handedness\n",
    "#   annotated_image = np.copy(rgb_image)\n",
    "\n",
    "#   # Loop through the detected hands to visualize.\n",
    "#   for idx in range(len(hand_landmarks_list)):\n",
    "#     hand_landmarks = hand_landmarks_list[idx]\n",
    "#     handedness = handedness_list[idx]\n",
    "\n",
    "#     # Draw the hand landmarks.\n",
    "#     hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "#     hand_landmarks_proto.landmark.extend([\n",
    "#       landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in hand_landmarks\n",
    "#     ])\n",
    "    \n",
    "#     solutions.drawing_utils.draw_landmarks(\n",
    "#       annotated_image,\n",
    "#       hand_landmarks_proto,\n",
    "#       solutions.hands.HAND_CONNECTIONS,\n",
    "#       solutions.drawing_styles.get_default_hand_landmarks_style(),\n",
    "#       solutions.drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "#     # Get the top left corner of the detected hand's bounding box.\n",
    "#     height, width, _ = annotated_image.shape\n",
    "#     x_coordinates = [landmark.x for landmark in hand_landmarks]\n",
    "#     y_coordinates = [landmark.y for landmark in hand_landmarks]\n",
    "#     text_x = int(min(x_coordinates) * width)\n",
    "#     text_y = int(min(y_coordinates) * height) - MARGIN\n",
    "\n",
    "#     # Draw handedness (left or right hand) on the image.\n",
    "#     cv2.putText(annotated_image, f\"{handedness[0].category_name}\",\n",
    "#                 (text_x, text_y), cv2.FONT_HERSHEY_DUPLEX,\n",
    "#                 FONT_SIZE, HANDEDNESS_TEXT_COLOR, FONT_THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "#   return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e37490a-974f-4123-a246-6f58a6400ed0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:38:20.371063Z",
     "iopub.status.busy": "2024-03-24T12:38:20.370669Z",
     "iopub.status.idle": "2024-03-24T12:38:20.408498Z",
     "shell.execute_reply": "2024-03-24T12:38:20.407483Z",
     "shell.execute_reply.started": "2024-03-24T12:38:20.371028Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import mediapipe as mp\n",
    "# from mediapipe import solutions\n",
    "# from mediapipe.framework.formats import landmark_pb2\n",
    "# from mediapipe.tasks import python\n",
    "# from mediapipe.tasks.python import vision\n",
    "\n",
    "# base_options = python.BaseOptions(model_asset_path='hand_landmarker.task')\n",
    "# running_mode =  vision.RunningMode('VIDEO')\n",
    "# options = vision.HandLandmarkerOptions(base_options=base_options,\n",
    "#                                        num_hands=2)\n",
    "# detector = vision.HandLandmarker.create_from_options(options)\n",
    "\n",
    "# cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# # Load the frame rate of the video using OpenCV's CAP_PROP_FPS\n",
    "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "    \n",
    "#     # Convert the frame to RGB\n",
    "#     rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "#     # Convert the frame to MediaPipe's Image object\n",
    "#     image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
    "    \n",
    "#     # Get the timestamp for the current frame\n",
    "#     frame_timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "\n",
    "#         # STEP 4: Detect hand landmarks from the input image.\n",
    "#     detection_result = detector.detect(image)\n",
    "\n",
    "#     # # STEP 5: Process the classification result. In this case, visualize it.\n",
    "#     annotated_image = draw_landmarks_on_image_new(image.numpy_view(), detection_result)\n",
    "#     annotated_image_color = cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#     cv2.imshow('Annotated Image', annotated_image_color)\n",
    "   \n",
    "    \n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#          break\n",
    "\n",
    "# # Release the video capture object and close all windows\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
